{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">INFO 6105 Data Science Eng Methods and Tools, Lecture 7 Day 2</div>\n",
    "<div style=\"text-align: right\">Dino Konstantopoulos, 10 March 2022, with material from Peter Norvig and Chris Fonnesbeck</div>\n",
    "\n",
    "# Bayesian statistical analysis and probabilistic programming\n",
    "\n",
    "We now know how to use analytical parametric pdfs with known properties, and to match them with empirical data in order to zero in on the right parameters. It involves a bit of math (MOM), or a lot of math (MLE) for better estimates. The parameters are **point estimates**, the **data model** is **frequentist**, and we have little idea of the error we're making. The KS test does give us an idea, but how do we know where to draw the line on the p-value?\n",
    "\n",
    "Today, we'll detail an **algorithmic approach** and a **Bayesian model** to do the same thing, but we'll also get a ***much better estimate of the error we're making*** in picking our parameters. Next week, we'll also *explore* that algorithm.\n",
    "\n",
    "A frequentist model is described by an analytic function and its parameters. The method for solving for the model gives us what the most likely values for the parameters. A **Bayesian model** has parameters too, but it yields **uncertainty** about those parameters. The model is described as a probability distribution, just like frequentist models, but the uncertainly in its parameters is *also* described as probability distributions. How wild is that?! The model is a pdf, and its parameters are *also* pdfs!\n",
    "\n",
    "Run the cell below, we'll use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "RANDOM_SEED = 20090425"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian vs Frequentist Statistics: *What's the difference?*\n",
    "\n",
    "*Any* statistical inference scheme, Bayesian or otherwise, involves at least the following: \n",
    "\n",
    "1. Some **unknown quantities**, which we are interested in learning or predicting. These are called the **dependent variables**\n",
    "2. Some **data** which have been observed, and hopefully contains information leading to the dependent variables. These are called the **independent variables**. Note that some of these may be **correlated** with themselves (linearly or not), so we should be able to throw the correlated ones and only use the ***really independent variables*** for predicting the dependent ones\n",
    "3. One (or more) **models** that relate the independent variables to the dependent variables via a probablity distribution function (pdf). The pdf will yield **variates** that essentialy statistically ***look like the real data***. \n",
    "\n",
    "The model is the instrument you use to **learn** about the underlying process that yields the data. For example, you learn about the real world from the model that your parents build for you then teach you, before you leave home to build your own models. Machines build models to learn, too. They either learn them from the data, or we (humans) can also teach them the model, like parents to them! For example, we have meteorological models, which predict weather.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"ipynb.images/robot-daddy.jpg\" width=\"400\" />\n",
    "</center>\n",
    "\n",
    "In a **Frequentist** world view, **data** observed is considered **random**, because it is the realization of random processes and hence will vary each time one goes to observe the system. Model **parameters** are considered **fixed**. A parameter's true value may be as of yet unknown, but it's fixed. You need to wait till you have *all the data* before you can use methods to evaluate it.\n",
    "\n",
    "For example, Jesus Christ is a central parameter in the Christian World Model. Christians will say the world order may be random because of human misgivings, but Jesus Christ and his compassion (the parameter) is fixed and steadfast.\n",
    "\n",
    "In a frequentist world view, we take the winning scores of Lewis Hamilton from last season, and use these parameters as the ground truth for probabilities of wins this season. The wins may not match predictions, but that is because the world is **random**.\n",
    "\n",
    "In a **Bayesian** world view,  *data* is considered **fixed**. Model parameters may not be *completely* random, but Bayesians use probability distributions to describe their uncertainty in values, and are therefore treated as **random variables**. Model parameters *change all the time*, and as soon as you observe new evidence, you need to re-evaluate them!\n",
    "\n",
    "For example, some Christians may postulate that world order is predetermined, however Jesus Christ's compassion may vary because.. *sometimes he gets exasperated by his followers*!\n",
    "\n",
    "This analogy is *mine*, so if it's not very good, I apologize in advance! In my simple mind, it helps me understand what is *fixed*, and what is *variable*.\n",
    "\n",
    "In a Bayesian world view, the world is not random: There is a perfect scientific explanation for everything. However, the probabilities for CV winning ***change*** for every event. Sometimes she's on a winning streak, and other times on a losing streak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Formula\n",
    "\n",
    "While frequentist statistics uses different estimators for different problems, Bayes formula is the **only estimator** that Bayesians need to obtain estimates of unknown quantities. \n",
    "\n",
    "The equation expresses how our belief about the value of \\\\(\\theta\\\\) (the parameter), as expressed by the **prior distribution** \\\\(P(\\theta)\\\\) is reallocated following the observation of the data \\\\(y\\\\). \n",
    "\n",
    "For **discrete random variables**:\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "\\\\[Pr(\\theta\\;|\\;y) = \\frac{Pr(\\theta \\cap y)}{Pr(y)} = \\frac{Pr(y\\;|\\;\\theta)Pr(\\theta)}{\\sum_\\theta Pr(y\\;|\\;\\theta)Pr(\\theta)} \\\\]\n",
    "</div>\n",
    "\n",
    "The denominator is actually the expression in the numerator integrated over all possible discrete model parameters \\\\(\\theta\\\\).\n",
    "\n",
    "For **continuous random variables**, the denominator usually cannot be computed directly:\n",
    "\n",
    "<div style=\"font-size: 120%;\">  \n",
    "\\\\[Pr(\\theta\\;|\\;y) = \\frac{Pr(y\\;|\\;\\theta)Pr(\\theta)}{\\int Pr(y\\;|\\;\\theta)Pr(\\theta) d\\theta}\\\\]\n",
    "</div>\n",
    "\n",
    "The denominator is the expression in the numerator integrated over all possible continuous model parameters \\\\(\\theta\\\\)\n",
    "\n",
    "The **intractability** of the integral in the denominator was the reason for the under-utilization of Bayesian methods by statisticians for many years. But with the advent of computers and clever algorithms like [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm), this has changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M&Ms\n",
    "Remember this?\n",
    "\n",
    "> The blue M&M was introduced in 1995.  Before then, the color mix in a bag of plain M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  Afterward it was (24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown). \n",
    "A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996.  He won't tell me which is which, but he gives me one M&M from each bag.  One is yellow and one is green.  What is the probability that the yellow M&M came from the 1994 bag? Well, the old M&M bags' yellow count was higher, so it must be higher, right? But how to count?\n",
    "\n",
    "In a frequentist world view, you pick M&Ms the way we picked balls from our urns in our first lecture on probabilities. We just count all favorable outcomes and divide by all outcomes. No new experiment will change anything about that.\n",
    "\n",
    "In a Bayesian world view, experiments change *everything*.\n",
    "\n",
    "We are asked about the probability of an event (yellow_M&M94 + green_M&M96) given the evidence (M&M94 + M&M96 = {yellow, green}). The probability of the event is not readily available. However the probability of the evidence, given the event, is readily available!  \n",
    "\n",
    "***Before*** (prior) we see the colors of the M&Ms, there are two hypotheses, `A` and `B`, both with equal probability:\n",
    "\n",
    "    A: first M&M from 94 bag, second from 96 bag\n",
    "    B: first M&M from 96 bag, second from 94 bag\n",
    "    P(A) = P(B) = 0.5\n",
    "    \n",
    "***Then*** (posterior) we get some evidence:\n",
    "    \n",
    "    E: first M&M yellow, second green\n",
    "    \n",
    "We want to know the ***new*** (posterior) probability of hypothesis `A`, given the evidence:\n",
    "    \n",
    "    P(A | E)\n",
    "    \n",
    "That's not easy to calculate, except by enumerating the sample space (frequentist world view). But Bayes Theorem says:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E)\n",
    "    \n",
    "The quantities on the *right-hand-side* are easier to calculate:\n",
    "    \n",
    "    P(E | A) = 20/100 * 20/100 = 0.04\n",
    "    P(E | B) = 10/100 * 14/100 = 0.014\n",
    "    P(A)     = 0.5\n",
    "    P(B)     = 0.5\n",
    "    P(E)     = P(E | A) * P(A) + P(E | B) * P(B) \n",
    "             = 0.04     * 0.5  + 0.014    * 0.5   =   0.027\n",
    "             \n",
    "Where did the probability of the evidence P(E) formula come from?\n",
    "\n",
    "There are two possibilities of getting the evidence: A and B, a *union* and so we sum their probabilities. The joint probability of the evidence *and* case A is a succession or *intersection*, so it must be a product of their probabilities: P(E|A).P(A). Likewise for the case B: P(E|B).P(B) \n",
    "    \n",
    "And so here is how Bayes helps us get a final answer:\n",
    "    \n",
    "    P(A | E) = P(E | A) * P(A) / P(E) \n",
    "             = 0.04     * 0.5  / 0.027 \n",
    "             = 0.7407407407\n",
    "             \n",
    "This is the **posterior** probability that A came from the '94 bag, given an event, which changed our world view that the probability was 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In search of the model parameter $\\theta \\;$\n",
    "\n",
    "Suppose we are given some data and we are told that there is a process that yields this data, and which we must try to model. So we must \n",
    "- 1: Pick the right pdf from the catalogue, and \n",
    "- 2: Determine the right $\\theta$s for the data. \n",
    "\n",
    "More specifically, we are concerned with *beliefs* about what the $\\theta$s might be: Rather than guessing the $\\theta$s exactly, we talk about what $\\theta$s are ***likely to be*** by assigning a probability distribution to them!\n",
    "\n",
    "But these probability distributions are hidden from us. We see only see the data, and must ***go backwards*** to try and determine the $\\theta$s to build the best possible model of our data. This problem is **difficult** because there is no one-to-one mapping from the data to the $\\theta$s. \n",
    "\n",
    "In classical statistics we use the Method of Moments (MOM), and Maximum Likelihood Estimation (MLE), to get **point estimates** (not pdfs) for $\\theta$.\n",
    "\n",
    "In the Bayesian approach, we use **probabilistic programming** to solve this problem, with **Markov Chain Monte Carlo** (MCMC) methods and variational inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Bayesian Model for 2 groups with continuous outcome\n",
    "\n",
    "Let's do statistical inference for two groups (two statistics), with continuous random variables. \n",
    "\n",
    "We'll use the fictitious example from [Kruschke (2012)](http://www.indiana.edu/~kruschke/articles/KruschkeAJ2012.pdf) concerning the evaluation of a clinical trial for drug evaluation. The trial aims to evaluate the efficacy of a \"*smart drug*\" that is supposed to increase intelligence by comparing IQ scores of individuals in a treatment arm (those receiving the drug) to those in a control arm (those recieving a placebo). There are 47 individuals and 42 individuals in the treatment (`drug`) and control (`placebo`) arms, respectively, and these are their post-trial IQs. An IQ between 90 and 110 is considered average; over 120, superior. Let's look at the histograms of our data, first thing you should always do.\n",
    "\n",
    "Note that although our IQ data is integer type, our datasets here could easily be real-valued, and so we consider our random variable to be continuous.\n",
    "\n",
    "Please plot histograms using `pd.concat([drug, placebo], ignore_index=True)`, and then `.hist('iq', by='group')` on the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'drug'}>,\n",
       "       <AxesSubplot:title={'center':'placebo'}>], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug = pd.DataFrame(dict(iq=(101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,\n",
    "        109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,\n",
    "        96,103,124,101,101,100,101,101,104,100,101),\n",
    "                         group='drug'))\n",
    "placebo = pd.DataFrame(dict(iq=(99,101,100,101,102,100,97,101,104,101,102,102,100,105,88,101,100,\n",
    "           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,\n",
    "           101,100,99,101,100,102,99,100,99),\n",
    "                            group='placebo'))\n",
    "\n",
    "trial_data = pd.concat([drug, placebo], ignore_index=True)\n",
    "trial_data.hist('iq', by='group')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Student-T distribution\n",
    "\n",
    "Hmm... there appears to be extreme (\"outlier\") values in the data (bins on the left and/or right that are distant from where most of the data lies, we say the data \"*has wings*). That is a good indicator to pick a new pdf from our catalogue of all possible pdfs, called the [Student-t](https://en.wikipedia.org/wiki/Student%27s_t-distribution) distribution, to describe the distributions of the scores in each group. \n",
    "\n",
    "It was developed by [William Sealy Gosset](https://en.wikipedia.org/wiki/William_Sealy_Gosset) under the pseudonym `Student`. That's because William worked for Guiness, and Guiness was very worried about its secret Beer formula. Another researcher at Guinness had previously published a paper containing trade secrets of the Guinness brewery. To prevent further disclosure of confidential information, Guinness prohibited its employees from publishing any papers regardless of the contained information. So William published his results with a pseudonym. \n",
    "\n",
    "Another researcher, [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) introduced a new form of that statistic, denoted `t`. The t-form was adopted because it fit in with Fisher's theory of degrees of freedom. And so now we're stuck with the mysteriously-named `Student-t` distribution, which works great modeling histograms ***with outliers*** (like financial data!).\n",
    "\n",
    "</br >\n",
    "<center>\n",
    "<img src=\"ipynb.images/guiness.jpg\" width=200 />\n",
    "</center>\n",
    "\n",
    "This sampling distribution adds **robustness** to the analysis, as a `T distribution` is less sensitive to outlier observations, relative to a `normal` distribution. In other words, if you have ***a lot of outliers*** in your data and attempt to model your data with a normal distribution, your outliers will *skew* your model so that it does not fit the non-outlier data very well.\n",
    "\n",
    "The **three-parameter** Student-t distribution allows for the specification of the following $\\theta$s: A mean $\\mu$, a precision (inverse-variance) $\\lambda$, and a degrees-of-freedom parameter $\\nu$:\n",
    "\n",
    "$$f(x\\;|\\;\\mu,\\lambda,\\nu) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\Gamma(\\frac{\\nu}{2})} \\left(\\frac{\\lambda}{\\pi\\nu}\\right)^{\\frac{1}{2}} \\left[1+\\frac{\\lambda(x-\\mu)^2}{\\nu}\\right]^{-\\frac{\\nu+1}{2}}$$\n",
    "           \n",
    "where $\\Gamma$ denotes the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function), an extension of the factorial function (with its argument shifted down by 1) to real and complex numbers, and not to be confused with the (lower-case) maximum entropy [$\\gamma$ distribution](https://en.wikipedia.org/wiki/Gamma_distribution) used to model rainfalls and insurance claims. This class will, if anything, teach you the greek alphabet!\n",
    "\n",
    "The degrees-of-freedom parameter essentially specifies the \"***normality***\" of the data, since larger values of $\\nu$ make the distribution converge to a normal distribution, while small values (close to zero) result in heavier tails.\n",
    "\n",
    "Thus, the likelihood functions of our model will be specified as follows (since we seem to have outliers in our observations of IQ):\n",
    "\n",
    "$$\\begin{align}\n",
    "y^{(drug)}_i &\\sim T(\\nu, \\mu_1, \\sigma_1) \\\\\n",
    "y^{(placebo)}_i &\\sim T(\\nu, \\mu_2, \\sigma_2)\n",
    "\\end{align}$$\n",
    "\n",
    "As a simplifying assumption, we will assume that the degree of normality $\\nu$ is the same for both groups (both groups with similar outlier statistics). \n",
    "\n",
    "### Exercise\n",
    "First:\n",
    "```(python)\n",
    "pip install pymc3\n",
    "```\n",
    "\n",
    "Now, draw 10,000 samples from a Student-T distribution (`StudentT` in PyMC3) with parameter `nu=3` and compare the distribution of these values to a similar number of draws from a `Normal` distribution with parameters `mu=0` and `sd=1`. The distribution is denoted `StudentT` in `pymc3`, while the normal distribution is denoted by `Normal`. So, `StudentT.dist(nu=3)` and `Normal.dist(0,1)`. Getting a random sampling of 10,000 datapoints can be achieved with `.random(size=10000)`. Plot with `seaborn` using `.distplot()`, from -10 to 10. You should find that the Student-T is more spread out and has a lower peak than the Gaussian. Import the Student-T distribution and the Normal distribution from pymc3: `from pymc3 import StudentT, Normal`. Then, draw 10,000 random variates from Student-T: `StudentT.dist(nu=3).random(size=10000)`, and 10,000 random variates from a gaussian: `Normal.dist(0,1).random(size=10000)`. Use `seagram` to plot both histograms on top of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"divCheckbox\" style=\"display: none;\">\n",
    "from pymc3 import StudentT, Normal\n",
    "\n",
    "t = StudentT.dist(nu=6).random(size=10000)\n",
    "n = Normal.dist(0,1).random(size=10000)\n",
    "\n",
    "sns.distplot(t, label='Student-T')\n",
    "sns.distplot(n, label='Gaussian')\n",
    "plt.legend()\n",
    "plt.xlim(-10,10)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeeni\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\zeeni\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-10.0, 10.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymc3 import StudentT, Normal\n",
    "\n",
    "t = StudentT.dist(nu=3).random(size=10000)\n",
    "n = Normal.dist(0,1).random(size=10000)\n",
    "\n",
    "sns.distplot(t, label='Student-T')\n",
    "sns.distplot(n, label='Gaussian')\n",
    "plt.legend()\n",
    "plt.xlim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing PyMC3\n",
    "-----\n",
    "\n",
    "`PyMC3` is a Python library for programming Bayesian analysis; see [here](https://doi.org/10.7717/peerj-cs.55). It's a wonderful package. Looky [here](https://docs.pymc.io/) for its API and docs. It helps us solve tough inverse problems and extract a model from the data.\n",
    "\n",
    "We will model our problem using PyMC3. This type of programming is called ***probabilistic programming***, and it is probabilistic in that we create probability models using programming variables as the model's components. Model components are first-class primitives within the PyMC3 framework. \n",
    "\n",
    ">   Another way of thinking about this: unlike a traditional program, which only runs in the forward direction, a probabilistic program runs in ***both*** forward and backward directions. It runs forward to compute consequences of assumptions it contains about the model, but also backward from the data to constrain possible explanations. In practice, many probabilistic programming systems will cleverly interleave forward and backward operations to efficiently home in on the best explanations.  - [Cronin, Beau. \"Why Probabilistic Programming Matters.\" 24 Mar 2013. Google, Online Posting to Google . Web. 24 Mar. 2013]( https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1)\n",
    "\n",
    "PyMC3 used to rely on [**theano**](https://en.wikipedia.org/wiki/Theano_(software)), a Python library that allows one to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently, and which we will revisit when we focus on machine learning. Theano is the brainchild of [Yoshua Benjio](https://en.wikipedia.org/wiki/Yoshua_Bengio) of the University of Montreal's [MILA](https://mila.quebec/en/) laboratory. In my opinion, it's the most famous university lab associated to artificial neural networks and deep learning. It's pretty [well-funded](http://nouvelles.umontreal.ca/en/article/2017/09/15/facebook-invests-over-7m-u.s.-in-mila-and-ai-research-in-montreal/).\n",
    "\n",
    "`theano` is now deprecated because other libraries like facebook's `Torch` and Google's `TensorFlow` now include the same features. Older PyMC3 versions still uses theano, but the newer versions don't, they use [**tensorflow**](https://en.wikipedia.org/wiki/TensorFlow) instead.\n",
    "\n",
    "For probabilistic programming, you write a program in Python that builds expressions for Theano. You still have to declare variables $a,b,c$ and give their types $(int, int, int)$, build expressions for how to put those variables together $a^b + c$, and compile expression graphs to functions $Pow(a,b,c)$ in order to use them for computation. What theano builds in return is a super-fast callable object from a purely symbolic graph, optimizes the graph, and even compiles some or all of it into native machine instructions. More on Theano [here](http://www.deeplearning.net/software/theano/). \n",
    "\n",
    "For older theano versions of PyMC3, we needed to do this (don't do this if you're using a new version):\n",
    "- On Windows, from the Start menu, search for and open `Anaconda Prompt`. On MacOS, open Launchpad, then click the Terminal icon. On Linux, open a Terminal window. Now in these windows, type `conda install -c mila-udem theano pygpu`. Don't try `!conda install theano` in a jupyter notebook code cell because it may fry your jupyter notebook's kernel. Wait until success. Then in that same terminal, type `conda install pymc3`. Wait until success.\n",
    "\n",
    "PyMC3 code is easy to read. The only novel thing is the syntax. Simply remember that we are representing the model's components ($\\tau, \\lambda_1, \\lambda_2$ ) as **probabilistic variables**. And the way we represent *continuous* probabilistic variables is with a probability density function (pdf): A **function**, not a **dictionary** anymore.\n",
    "\n",
    ">**Note**: Do not confuse this/these function/s with the histogram of the dataset or the pdf that we will use to model it. That is a *different* function.\n",
    "\n",
    "To figure out these functions, we will first assume they have a certain shape, which we will call the **prior shape**.\n",
    "\n",
    "Then, we will run a simulation and try to approximate our data.\n",
    "\n",
    "This will allow us to refine the prior shapes into **posterior shapes**, in accordance with Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking our Priors\n",
    "\n",
    "We have an idea about the means of our IQ data: The data for both drug and placebo group seem to be centered around IQ = 100.\n",
    "\n",
    "So let's center the Student-T priors for $\\mu$ at 100, using a Normal distribution, and a standard deviation that is wide enough to account for plausible deviations from this population mean:\n",
    "\n",
    "$$\\mu_k \\sim N(100, 10^2)$$\n",
    "\n",
    "- *Craaaaazy*, right? I'm modeling data using a **Student-T pdf model** with 3 parameters and I model the first parameter using a **normal distribution** (pdf).\n",
    "\n",
    "Please do this below using:\n",
    "```python\n",
    "from pymc3 import Model, Uniform\n",
    "\n",
    "with Model() as drug_model:\n",
    "    μ_0 = Normal('μ_0', 100, sd=10)\n",
    "    μ_1 = Normal('μ_1', 100, sd=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pymc3 import Model, Uniform\n",
    "\n",
    "with Model() as drug_model:\n",
    "    μ_0 = Normal('μ_0', 100, sd=10)\n",
    "    μ_1 = Normal('μ_1', 100, sd=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a Uniform prior for the standard deviations $\\sigma_k$ of the Student-T, with a lower bound of 0 and an upper bound of 20, here below:\n",
    "```(python)\n",
    "with drug_model:\n",
    "    σ_0 = Uniform('σ_0', lower=0, upper=20)\n",
    "    σ_1 = Uniform('σ_1', lower=0, upper=20)\n",
    "```\n",
    "\n",
    "- *Craaaazy*! I use a **uniform distribution** (pdf) to model the second parameter of the pdf-based model (standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with drug_model:\n",
    "    σ_0 = Uniform('σ_0', lower=0, upper=20)\n",
    "    σ_1 = Uniform('σ_1', lower=0, upper=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the degrees-of-freedom parameter $\\nu$, use an exponential distribution with a mean of 30. \n",
    "```python\n",
    "from pymc3 import Exponential\n",
    "sns.distplot(Exponential.dist(1/29).random(size=10000), kde=False);\n",
    "```\n",
    "\n",
    "- *Craaazy*! I use an **exponential distribution** to model the third parameter of my **student-T model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pymc3 import Exponential\n",
    "sns.displot(Exponential.dist(1/29).random(size=10000), kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allocates ***high prior probability*** over the regions of the parameter that describe the range from normal to heavy-tailed data under the Student-T distribution:\n",
    "```python\n",
    "with drug_model:\n",
    "    ν = Exponential('ν_minus_one', 1/29.) + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable name ν_minus_one_o_log__ already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2744/4089834350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mdrug_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mν\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ν_minus_one_o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m29.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getnewargs__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36mVar\u001b[1;34m(self, name, dist, data, total_size, dims)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m                     var = TransformedRV(\n\u001b[0m\u001b[0;32m   1143\u001b[0m                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                         \u001b[0mdistribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, type, owner, index, name, distribution, model, transform, total_size)\u001b[0m\n\u001b[0;32m   2010\u001b[0m             \u001b[0mtransformed_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_transformed_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2012\u001b[1;33m             self.transformed = model.Var(\n\u001b[0m\u001b[0;32m   2013\u001b[0m                 \u001b[0mtransformed_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36mVar\u001b[1;34m(self, name, dist, data, total_size, dims)\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_random_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36madd_random_variable\u001b[1;34m(self, var, dims)\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;34m\"\"\"Add a random variable to the named variables of the model.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_contains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Variable name {var.name} already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable name ν_minus_one_o_log__ already exists."
     ]
    }
   ],
   "source": [
    "with drug_model:\n",
    "    ν = Exponential('ν_minus_one_o', 1/29.) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go ahead and model both datasets in `pymc3`:\n",
    "```python\n",
    "with drug_model:\n",
    "    drug_like = StudentT('drug_like', nu=ν, mu=μ_1, lam=σ_1**2, observed=drug.iq)\n",
    "    placebo_like = StudentT('placebo_like', nu=ν, mu=μ_0, lam=σ_0**2, observed=placebo.iq)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with drug_model:\n",
    "    drug_like_1 = StudentT('drug_like_1', nu=ν, mu=μ_1, lam=σ_1**2, observed=drug.iq)\n",
    "    placebo_like_1 = StudentT('placebo_like_1', nu=ν, mu=μ_0, lam=σ_0**2, observed=placebo.iq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn your attention now to tracking the **posterior** ***quantities of interest***. Namely, calculate the difference in means between the drug and placebo groups: `diff_of_means = Deterministic('difference of means', μ_1 - μ_0)`. \n",
    "\n",
    "As a joint measure of the groups, also estimate the [**effect size**](https://en.wikipedia.org/wiki/Effect_size), which is the difference in means scaled by the pooled (square root of the squares) estimates of standard deviation: `Deterministic('effect size', diff_of_means / np.sqrt((σ_1**2 + σ_0**2) / 2))`. \n",
    "\n",
    "The effect size resembles the computation for a t-test statistic, with the critical difference that the t-test statistic includes a factor of ${\\sqrt {n}}$. This means that for a given effect size, the significance level increases with the sample size. Unlike the t-test statistic, the effect size aims to estimate a population parameter and is not affected by the sample size (yay!). Effect size can be harder to interpret, since it is no longer in the same units as our data, but it is a function of all four estimated parameters.\n",
    "\n",
    "We need to specify `Deterministic` because all PyMC3 variables are by default **probabilistic**, unless we set them to be **deterministic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Deterministic\n",
    "    \n",
    "with drug_model:\n",
    "    diff_of_means = Deterministic('difference of means', μ_1 - μ_0)\n",
    "    effect_size = Deterministic('effect size', diff_of_means / np.sqrt((σ_1**2 + σ_0**2) / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, all right, all right! Now our model is **fully specified** and we are ready to track our posteriors.\n",
    "\n",
    "<br />\n",
    "<center>\n",
    "<img src=\"https://media1.tenor.com/images/c4b036354e1a6e6fedd3809a0c945003/tenor.gif?itemid=5146096\" width=\"400\" />\n",
    "All right, all right, all right\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit the model using [**variational inference**](https://en.wikipedia.org/wiki/Variational_Bayesian_methods). This will estimate all our posterior distributions using an optimized approximation, and then draw 1,000 samples from it. Be *patient* now, we are running **probabilistic regressions**.\n",
    "```python\n",
    "from pymc3 import fit\n",
    "\n",
    "with drug_model: \n",
    "    drug_trace = fit(random_seed=RANDOM_SEED).sample(1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10000/10000 09:35<00:00 Average Loss = 973.47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 972.35\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Ambiguous name: ν_minus_one_log__ - please check the names of the inputs of your function for duplicates.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2744/778399197.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mdrug_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdrug_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\variational\\opvi.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, draws, include_transformed)\u001b[0m\n\u001b[0;32m   1623\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m         trace = NDArray(\n\u001b[0m\u001b[0;32m   1626\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m             \u001b[0mvars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvars_sampled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\backends\\ndarray.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, model, vars, test_point)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_point\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\backends\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, model, vars, test_point)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mtest_point_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mtest_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_point_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mvar_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_values\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_dtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_values\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1548\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function\\types.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# for speed, skip the items for empty kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function\\types.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function\\types.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m    507\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Unknown input or state: {item}. {msg}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mDUPLICATE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                     raise TypeError(\n\u001b[0m\u001b[0;32m    510\u001b[0m                         \u001b[1;34mf\"Ambiguous name: {item} - please check the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                         \u001b[1;34m\"names of the inputs of your function \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Ambiguous name: ν_minus_one_log__ - please check the names of the inputs of your function for duplicates."
     ]
    }
   ],
   "source": [
    "\n",
    "from pymc3 import fit\n",
    "\n",
    "with drug_model: \n",
    "    drug_trace = fit(random_seed=RANDOM_SEED).sample(1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Waaaaait*** for the probabilistic computation to finish!\n",
    "\n",
    ">**Note**: You *may* have to speify the extra argument (inside the `fit()` API): `cores = 1` if your laptop does not have the power to run all 4 cores (the *old* API analog was `njobs = 1`)\n",
    "\n",
    "Now plot all your posterior distributions, throwing away the first 100 samples. You typically always throw away from 10% to 20% of your simulation samples, because they start off *wrong* before converging to the *right solution*:\n",
    "```python\n",
    "from pymc3 import plot_posterior\n",
    "\n",
    "plot_posterior(drug_trace[100:], \n",
    "                varnames=['μ_0', 'μ_1', 'σ_0', 'σ_1', 'ν_minus_one'],\n",
    "                color='#87ceeb');\n",
    "```\n",
    "\n",
    "and in the next cell:\n",
    "```python\n",
    "plot_posterior(drug_trace[100:], \n",
    "          varnames=['difference of means', 'effect size'],\n",
    "          ref_val=0,\n",
    "          color='#87ceeb');\n",
    "```\n",
    "\n",
    "if you have import errors on `plot_posterior`, chances are the APIs got moved to another library. So do this instead:\n",
    "```(python)\n",
    "pip install arviz\n",
    "from arviz import plot_posterior\n",
    "```\n",
    "\n",
    "Also, possible that `varnames` was renamed to `var_names`.\n",
    "\n",
    "In any case, any error, please google the error. If not solution, let us know :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drug_trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2744/363028968.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_posterior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m plot_posterior(drug_trace[100:], \n\u001b[0m\u001b[0;32m      4\u001b[0m                 \u001b[0mvarnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'μ_0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'μ_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'σ_0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'σ_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ν_minus_one'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 color='#87ceeb');\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drug_trace' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymc3 import plot_posterior\n",
    "\n",
    "plot_posterior(drug_trace[100:], \n",
    "                varnames=['μ_0', 'μ_1', 'σ_0', 'σ_1', 'ν_minus_one'],\n",
    "                color='#87ceeb');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_posterior(drug_trace[100:], \n",
    "          varnames=['difference of means', 'effect size'],\n",
    "          ref_val=0,\n",
    "          color='#87ceeb');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, *conclude* please.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:none;\">\n",
    "- Conclusion: The posterior probability that the mean IQ of the subjects in the treatment group is greater than that of the placebo group is left of zero. That means that all the probability that the drug *worked* is concentrated beyond the null hypothesis (0), the effect of the drug is around 30%, and the most probable value in the difference between the drug group and the control group is a difference of 1 in the first parameter of the model assumed. So the IQ drug *worked*!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conclusion: The posterior probability ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "- Find a single-humped dataset on the Web. The most original datasets will get the highest bonuses. \n",
    "- Figure out the best possible match using the mathematical functions we learned about. Use Math and MLE to find the best parameters.\n",
    "- Now, repeat the experiment with programming and PyMC3.\n",
    "- Which method was the most fun?\n",
    "\n",
    "## References and Resources\n",
    "\n",
    "- Goodman, S. N. (1999). Toward evidence-based medical statistics. 1: The P value fallacy. Annals of Internal Medicine, 130(12), 995–1004. http://doi.org/10.7326/0003-4819-130-12-199906150-00008\n",
    "- Johnson, D. (1999). The insignificance of statistical significance testing. Journal of Wildlife Management, 63(3), 763–772.\n",
    "- Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis, Third Edition. CRC Press.\n",
    "-  Norvig, Peter. 2009. [The Unreasonable Effectiveness of Data](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf).\n",
    "- Salvatier, J, Wiecki TV, and Fonnesbeck C. (2016) Probabilistic programming in Python using PyMC3. *PeerJ Computer Science* 2:e55 <https://doi.org/10.7717/peerj-cs.55>\n",
    "- Cronin, Beau. \"Why Probabilistic Programming Matters.\" 24 Mar 2013. Google, Online Posting to Google . Web. 24 Mar. 2013. <https://plus.google.com/u/0/107971134877020469960/posts/KpeRdJKR6Z1>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
